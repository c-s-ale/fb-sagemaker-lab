{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Today you are a Machine Learning Engineer at Walmart!\n",
    "For your latest assignemt, your manager has asked your team to work alongside the Data Engineering team to design an optimal Machine Learning pipeline for Automated Inventory, i.e. predicting purchases per customer accurately. The Data Engineering team has provided you with some clean online shopping data gathered from the servers over the last few months. \n",
    "\n",
    "You are expected to successfully complete the following tasks:\n",
    "\n",
    "\n",
    "1. EDA - Feature Selection\n",
    "2. Build, and evaluate, a Classifier using Sagemaker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. **Introduction**\n",
    "    1. Imports\n",
    "    2. Loading the Data\n",
    "2. **Task 1: Perform Exploratory Data Analysis (EDA)**\n",
    "    1. Method 1: RandomForestClassifier Feature Importance\n",
    "    2. Method 2: Select KBest\n",
    "    3. Trimming the Data and EDA Cont.\n",
    "3. **Task 2: Build a classifier model training pipeline with Sagemaker**\n",
    "    1. Step 1: Write Data to S3  \n",
    "    2. Convenience Functions\n",
    "    3. Step 2: Initiate model training pipeline\n",
    "        1. *Option 1*\n",
    "        2. *Option 2*\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Imports\"></a>\n",
    "### Imports\n",
    "Your first step should always be: Importing required libraries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.feature_selection as fs\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "import sagemaker.amazon.common as smac\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.image_uris import retrieve as retrieve_image_uris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"LoadingData\"></a>\n",
    "### Loading the data\n",
    "\n",
    "Since our data engineers have provided us with clean data by means of a `.csv` file, we can simply read it into a `pd.Dataframe`!\n",
    "\n",
    "> **A note on data and SageMaker:**\n",
    ">\n",
    ">  One of the benefits of using a tool like Sagemaker, especially in conjuction with S3 and other remote storage options, is that you don't have to ever actually store data on your local machine. This can help a lot when it comes to data privacy considerations, and is a huge benefit to a remote cloud based ML solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data=pd.read_csv('./preproc_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The data has {raw_data.shape[0]} rows and {raw_data.shape[1]} columns\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the Data Engineering team has sent over ~1M records corresponding to users and their interactions with products. Notice two things:\n",
    "1. All features are numeric (so the data has already been 1 hot encoded).\n",
    "2. The last column depicts if the user-product interation resulted in a purchase or not.\n",
    "\n",
    "\n",
    "This kind of data is referred to as a \"user journey\"!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Perform Exploratory Data Analysis (EDA) to find features that are important. \n",
    "You can choose any one of (or both of) the two methods given below.\n",
    "\n",
    "\n",
    "1. [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) for feature importance that uses Entropy based measure called GINI Index to rank features of importance\n",
    "\n",
    "2. [SelectKBest](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html) method using the sklearn feature_selection library\n",
    "\n",
    "\n",
    "Observe some differences in the ranked methods!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the `raw_data` DataFrame into XData (minus the two 'index columns' of `user_id` and `product_id`) and YData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "XData = raw_data.iloc[:,2:-1]\n",
    "YData = raw_data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and test data, stratifying across YData to ensure equal proportion labels in the training/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(XData,YData,test_size=0.2,random_state=42, stratify=YData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you'll want to scale the data using [this](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html?highlight=minmax#sklearn.preprocessing.MinMaxScaler) approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMscaler = MinMaxScaler()\n",
    "X_train = MMscaler.fit_transform(X_train)\n",
    "X_test = MMscaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1: RandomForestClassifier Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize, and fit a RandomForestClassifer estimator for use in finding feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = SelectFromModel(RandomForestClassifier(n_estimators = 10))\n",
    "sel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you'll want to get the feature importances from the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = sel.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the selected features by importance in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(importances)[::-1] \n",
    "colname = XData.columns[indices]\n",
    "plt.figure(figsize=(15,9))\n",
    "plt.title(\"Feature importances\",size=20)\n",
    "sns.barplot(x=colname, y=importances[indices],palette=\"deep\")\n",
    "plt.xticks(rotation=90,size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: SelectKBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you'll want to grab the `k = num features` best features, fit SelectKBest and get a list of feature names and scores!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb = fs.SelectKBest(k=X_train.shape[1])\n",
    "kb.fit(X_train, y_train)\n",
    "names = XData.columns.values[kb.get_support()]\n",
    "scores = kb.scores_[kb.get_support()]\n",
    "names_scores = list(zip(names, scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the selected features by importance in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fScoreDF = pd.DataFrame(data = names_scores, columns=['Feat_names','F_Scores'])\n",
    "fScoreDF_sorted = fScoreDF.sort_values(['F_Scores','Feat_names'], ascending =[False, True])\n",
    "plt.figure(figsize=(15,9))\n",
    "sns.barplot(x= \"Feat_names\", y=\"F_Scores\",data=fScoreDF_sorted)\n",
    "plt.xticks(rotation=90,size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trimming the Data and EDA Cont.\n",
    "Regardless of which feature importance method you select: You'll find that the temportal data provided does not contribute significantly to the result, so we can safely remove those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1=X_train[:,1:13]\n",
    "X_test_1=X_test[:,1:13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up, let's view the distribution of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.hist(y_train)\n",
    "plt.hist(y_test)\n",
    "plt.show()\n",
    "print(\"Fraction of Purchases in train data=\", np.sum(y_train)/np.shape(y_train)[0])\n",
    "print(\"Fraction of Purchases in test data=\", np.sum(y_test)/np.shape(y_test)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Build a classifier model training pipeline with Sagemaker.\n",
    "\n",
    "Finally, the time has come to build your model training pipeline!\n",
    "\n",
    "> **A note on AutoML and Autopilot**\n",
    "> \n",
    "> A key feature of SageMaker is SageMaker Autopilot, and automated-ML solution that can help you find and tune hyperparameters - and a lot more! While these kinds of features are great, and are an excellent tool in your toolbelt; they are also very compute/time intensive, which means they're outside of the scope of this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Write Data to S3  \n",
    "\n",
    "It's time for you to convert the processed training data to protobuf and write it to S3 for a [linear-learner](https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner.html) model pipeline using Sagemaker. \n",
    "\n",
    "Ensure the `bucket_new` variable is the S3 bucket you made earlier in the lab. (FIRSTNAMEmlops)\n",
    "\n",
    "In addition, make sure the `prefix` variable is set to your NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_new = None # replace None with <FIRSTNAME>mlops\n",
    "prefix = None # replace this with your own prefix <NAME>\n",
    "role = get_execution_role()\n",
    "\n",
    "s3_train_key = \"{}/train/recordio-pb-data\".format(prefix)\n",
    "s3_train_path = os.path.join(\"s3://\", bucket_new, s3_train_key)\n",
    "vectors = np.array([t.tolist() for t in X_train_1]).astype(\"float32\")\n",
    "labels = np.array(y_train).astype(\"float32\")\n",
    "buf = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(buf, vectors, labels)\n",
    "buf.seek(0)\n",
    "boto3.resource(\"s3\").Bucket(bucket_new).Object(s3_train_key).upload_fileobj(buf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convenience Functions\n",
    "\n",
    "The first convenience function will be a wrapper for training that takes in the S3 location of the training data, the model hyperparameters that define our training job, and the S3 output path for model artifacts. Inside the function, we'll hardcode the algorithm container, the number and type of EC2 instances to train on, and the input and output data formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor_from_hyperparams(s3_train_data, hyperparams, output_path):\n",
    "    \"\"\"\n",
    "    Create an Estimator from the given hyperparams, fit to training data, and return a deployed predictor\n",
    "    \"\"\"\n",
    "    # specify algorithm containers and instantiate an Estimator with given hyperparams\n",
    "    container = retrieve_image_uris(\"linear-learner\", boto3.Session().region_name)\n",
    "\n",
    "    linear = sagemaker.estimator.Estimator(\n",
    "        container,\n",
    "        role,\n",
    "        instance_count=1,\n",
    "        instance_type=\"ml.m4.xlarge\",\n",
    "        output_path=output_path,\n",
    "        sagemaker_session=sagemaker.Session(),\n",
    "    )\n",
    "    linear.set_hyperparameters(**hyperparams)\n",
    "    # train model\n",
    "    linear.fit({\"train\": s3_train_data})\n",
    "    # deploy a predictor\n",
    "    linear_predictor = linear.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")\n",
    "    #linear_predictor.content_type = \"csv\"\n",
    "    linear_predictor.serializer = CSVSerializer()\n",
    "    linear_predictor.deserializer = JSONDeserializer()\n",
    "    return linear_predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second convenience function is for setting up a hosting endpoint, making predictions, and evaluating the model. To make predictions, we need to set up a model hosting endpoint. Then we feed test features to the endpoint and receive predicted test labels. To evaluate the models we create in this exercise, we'll capture predicted test labels and compare them to actual test data using some common binary classification metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(linear_predictor, test_features, test_labels, model_name, verbose=True):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a test set given the prediction endpoint.  Return binary classification metrics.\n",
    "    \"\"\"\n",
    "    # split the test data set into 100 batches and evaluate using prediction endpoint\n",
    "    prediction_batches = [\n",
    "        linear_predictor.predict(batch)[\"predictions\"]\n",
    "        for batch in np.array_split(test_features, 100)\n",
    "    ]\n",
    "    # parse raw predictions json to exctract predicted label\n",
    "    test_preds = np.concatenate(\n",
    "        [np.array([x[\"predicted_label\"] for x in batch]) for batch in prediction_batches]\n",
    "    )\n",
    "\n",
    "    # calculate true positives, false positives, true negatives, false negatives\n",
    "    tp = np.logical_and(test_labels, test_preds).sum()\n",
    "    fp = np.logical_and(1 - test_labels, test_preds).sum()\n",
    "    tn = np.logical_and(1 - test_labels, 1 - test_preds).sum()\n",
    "    fn = np.logical_and(test_labels, 1 - test_preds).sum()\n",
    "\n",
    "    # calculate binary classification metrics\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    if verbose:\n",
    "        print(pd.crosstab(test_labels, test_preds, rownames=[\"actuals\"], colnames=[\"predictions\"]))\n",
    "        print(\"\\n{:<11} {:.3f}\".format(\"Recall:\", recall))\n",
    "        print(\"{:<11} {:.3f}\".format(\"Precision:\", precision))\n",
    "        print(\"{:<11} {:.3f}\".format(\"Accuracy:\", accuracy))\n",
    "        print(\"{:<11} {:.3f}\".format(\"F1:\", f1))\n",
    "\n",
    "    return {\n",
    "        \"TP\": tp,\n",
    "        \"FP\": fp,\n",
    "        \"FN\": fn,\n",
    "        \"TN\": tn,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1\": f1,\n",
    "        \"Model\": model_name,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last convenience function is to delete prediction endpoints after we're done with them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_endpoint(predictor):\n",
    "    try:\n",
    "        boto3.client(\"sagemaker\").delete_endpoint(EndpointName=predictor.endpoint)\n",
    "        print(\"Deleted {}\".format(predictor.endpoint))\n",
    "    except:\n",
    "        print(\"Already deleted: {}\".format(predictor.endpoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Initiate model training pipeline\n",
    "\n",
    "Next up you're going to set up a pipeline for training your model. \n",
    "\n",
    "You have two options:\n",
    "1. Option 1: A binary classifier (Linear Regression) with automated threshold tuning\n",
    "2. Option 2: A binary classifier with hinge loss, balanced class weights, and automated threshold tuning\n",
    "\n",
    "Both options will use \"Early Stopping Criteria\" (read more [here](https://github.com/aws/amazon-sagemaker-examples/blob/main/scientific_details_of_algorithms/linear_learner_class_weights_loss_functions/linear_learner_class_weights_loss_functions.ipynb)) with a target `Recall` of `0.8`. Since you're using early stopping, you don't have to worry as much about setting your Epochs too high and over training your model. Due to taking that into account, you can train the model for 10 epochs.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training Options\n",
    "---\n",
    "***ONLY SELECT ONE OPTION GOING FORWARD.***\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [OPTION 1]: Training a binary classifier (Logistic Regression) with automated threshold tuning\n",
    "\n",
    "autothresh_hyperparams = {\n",
    "    \"feature_dim\": 12,\n",
    "    \"predictor_type\": \"binary_classifier\",\n",
    "    \"binary_classifier_model_selection_criteria\": \"precision_at_target_recall\",\n",
    "    \"target_recall\": 0.8,\n",
    "    \"epochs\": 10,\n",
    "}\n",
    "autothresh_output_path = f\"s3://{bucket_new}/{prefix}/autothresh/output\"\n",
    "autothresh_predictor = predictor_from_hyperparams(\n",
    "    s3_train_path, autothresh_hyperparams, autothresh_output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [OPTION 1:] Evaluate the model\n",
    "predictors = {\n",
    "    \"Logistic with auto threshold\": autothresh_predictor,\n",
    "         \n",
    "}\n",
    "metrics = {\n",
    "    key: evaluate(predictor, X_test_1, y_test, key, False)\n",
    "    for key, predictor in predictors.items()\n",
    "}\n",
    "\n",
    "\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n",
    "display(\n",
    "    pd.DataFrame(list(metrics.values())).loc[:, [\"Model\", \"Recall\", \"Precision\", \"Accuracy\", \"F1\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [OPTION 2]: Training a binary classifier with hinge loss, balanced class weights, and automated threshold tuning\n",
    "linear_balanced_hyperparams = {\n",
    "    \"feature_dim\": 12,\n",
    "    \"predictor_type\": \"binary_classifier\",\n",
    "    \"loss\": \"hinge_loss\",\n",
    "    \"binary_classifier_model_selection_criteria\": \"precision_at_target_recall\",\n",
    "    \"target_recall\": 0.8,\n",
    "    \"positive_example_weight_mult\": \"balanced\",\n",
    "    \"epochs\": 10,\n",
    "}\n",
    "linear_balanced_output_path = f\"s3://{bucket_new}/{prefix}/linear_balanced/output\"\n",
    "linear_balanced_predictor = predictor_from_hyperparams(\n",
    "    s3_train_path, linear_balanced_hyperparams, linear_balanced_output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [OPTION 2:] Evaluate the model\n",
    "predictors = {\n",
    "    \"Hinge with class weights\": linear_balanced_predictor,\n",
    "    \n",
    "}\n",
    "metrics = {\n",
    "    key: evaluate(predictor, X_test_1, y_test, key, False)\n",
    "    for key, predictor in predictors.items()\n",
    "}\n",
    "\n",
    "\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n",
    "display(\n",
    "    pd.DataFrame(list(metrics.values())).loc[:, [\"Model\", \"Recall\", \"Precision\", \"Accuracy\", \"F1\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Now that you've trained your model, your can report your results back to your boss!\n",
    "\n",
    "Before you do, though, don't forget the most important step: Clean up!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up\n",
    "\n",
    "Make sure you delete your predictor endpoints using the convenience function below. \n",
    "\n",
    "Once you've completed the lab, please be sure to stop, and then delete, your Sagemaker Notebook instance - as well as remove the contents of, and delete, the S3 bucket you created!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, clean up all the predictors\n",
    "for predictor in [\n",
    "    autothresh_predictor,\n",
    "    linear_balanced_predictor,\n",
    "]:\n",
    "    delete_endpoint(predictor)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "635e31ff34c0350df6e9d804eda70786d94f48b17fcc73c378df4ea6ec0d01fd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('fourthbrain')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
