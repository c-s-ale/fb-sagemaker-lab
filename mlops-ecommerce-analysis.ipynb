{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Today you are a Machine Learning Engineer at Walmart!\n",
    "For your latest assignemt, your manager has asked your team to work alongside the Data Engineering team to design an optimal Machine Learning pipeline for Automated Inventory, i.e. predicting purchases per customer accurately. The Data Engineering team has used Trifacta to clean some online shopping data gathered from the servers over the last few months. \n",
    "\n",
    "You are expected to successfully complete the following tasks:\n",
    "\n",
    "\n",
    "    Task 1) EDA - find important information about the data\n",
    "    Task 2) Build a Classifier using Sagemaker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data\n",
    "In this assignment, we will read client data that has been pre-processed (using Trifacta), and stored in an S3 bucket name \"mlops-ecommerce\". Working off the S3 bucket directly allows you freedom to work from any workstation and also to maintain the integrity of the data sensitivity (no need to download on system)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start with loading the Libraries and loading the data\n",
    "import boto3\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import sagemaker\n",
    "import sagemaker.amazon.common as smac\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For this work, we'll need to load the data provided in the repo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "raw_data=pd.read_csv('./preproc_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing required Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the shape of the data\n",
    "np.shape(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print first few rows of the data\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So you see the Data Engineering team has sent you over 1M records corresponding to users and their interations with products. Notice two things:\n",
    "1. All features are nuueric (so one-hot-encoding has been done).\n",
    "2. Last column depicts if the user-product interation resulted in a purchase or not.\n",
    "Such kind of data is referred to as \"User Journeys\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Perform Exploratory Data Analysis (EDA) to find features that are important. \n",
    "You can choose any one of (or both of) the two methods given below.\n",
    "\n",
    "```\n",
    "Method 1: RandomForestClassifier for feature importance https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html that uses Entropy based measure called GINI Index to rank features of importance\n",
    "\n",
    "Method 2: Fisher scoring method using the sklearn feature_selection library https://scikit-learn.org/stable/modules/feature_selection.html\n",
    "```\n",
    "\n",
    "Observe some differences in the ranked mathods!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Libraries for Data splitting and normalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.feature_selection as fs\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the `raw_data` DataFrame into XData (minus the two index columns of `user_id` and `product_id`) and YData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "XData = raw_data.iloc[:,2:-1]\n",
    "YData = raw_data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and test data, stratifying across YData to ensure equal proportion labels in the training/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(XData,YData,test_size=0.2,random_state=42, stratify=YData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMscaler = MinMaxScaler()\n",
    "X_train = MMscaler.fit_transform(X_train)\n",
    "X_test = MMscaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize, and fit an estimator for use in finding feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = SelectFromModel(RandomForestClassifier(n_estimators = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feat= XData.columns[(sel.get_support())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = sel.estimator_.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(importances)[::-1] \n",
    "colname = XData.columns[indices]\n",
    "plt.figure(figsize=(15,9))\n",
    "plt.title(\"Feature importances\",size=20)\n",
    "sn.barplot(x=colname, y=importances[indices],palette=\"deep\")\n",
    "plt.xticks(rotation=90,size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb = fs.SelectKBest(k=X_train.shape[1])\n",
    "kb.fit(X_train, y_train)\n",
    "names = XData.columns.values[kb.get_support()]\n",
    "scores = kb.scores_[kb.get_support()]\n",
    "names_scores = list(zip(names, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fScoreDF = pd.DataFrame(data = names_scores, columns=['Feat_names','F_Scores'])\n",
    "fScoreDF_sorted = fScoreDF.sort_values(['F_Scores','Feat_names'], ascending =[False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,9))\n",
    "sn.barplot(x= \"Feat_names\", y=\"F_Scores\",data=fScoreDF_sorted)\n",
    "plt.xticks(rotation=90,size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thus, we observe that the temporal features (time, day, year etc) have significantly less importance than the other features. Thus, we reduce data dimensionality by discarding the temporal features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1=X_train[:,1:13]\n",
    "X_test_1=X_test[:,1:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next lets look at the data distribution\n",
    "plt.hist(y_train)\n",
    "plt.hist(y_test)\n",
    "plt.show()\n",
    "print(\"Fraction of Purchases in train data=\", np.sum(y_train)/np.shape(y_train)[0])\n",
    "print(\"Fraction of Purchases in test data=\", np.sum(y_test)/np.shape(y_test)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 [Instructor Led]: Build a classifier hyper-parameterization pipeline with Sagemaker for complete dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1:  Here, we convert the processed training data to protobuf and write to S3 for linear-learner in Sagemaker. Ensure the \"New bucket name\" is accurate in the cell underneath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_new = None # replace None with <FIRSTNAME>mlops\n",
    "prefix = None # replace this with your own prefix\n",
    "s3_train_key = \"{}/train/recordio-pb-data\".format(prefix)\n",
    "s3_train_path = os.path.join(\"s3://\", bucket_new, s3_train_key)\n",
    "vectors = np.array([t.tolist() for t in X_train_1]).astype(\"float32\")\n",
    "labels = np.array(y_train).astype(\"float32\")\n",
    "buf = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(buf, vectors, labels)\n",
    "buf.seek(0)\n",
    "boto3.resource(\"s3\").Bucket(bucket_new).Object(s3_train_key).upload_fileobj(buf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will wrap the model training setup in a convenience function that takes in the S3 location of the training data, the model hyperparameters that define our training job, and the S3 output path for model artifacts. Inside the function, we'll hardcode the algorithm container, the number and type of EC2 instances to train on, and the input and output data formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.image_uris import retrieve as retrieve_image_uris\n",
    "\n",
    "def predictor_from_hyperparams(s3_train_data, hyperparams, output_path):\n",
    "    \"\"\"\n",
    "    Create an Estimator from the given hyperparams, fit to training data, and return a deployed predictor\n",
    "    \"\"\"\n",
    "    # specify algorithm containers and instantiate an Estimator with given hyperparams\n",
    "    container = retrieve_image_uris(\"linear-learner\", boto3.Session().region_name)\n",
    "\n",
    "    linear = sagemaker.estimator.Estimator(\n",
    "        container,\n",
    "        role,\n",
    "        instance_count=1,\n",
    "        instance_type=\"ml.m4.xlarge\",\n",
    "        output_path=output_path,\n",
    "        sagemaker_session=sagemaker.Session(),\n",
    "    )\n",
    "    linear.set_hyperparameters(**hyperparams)\n",
    "    # train model\n",
    "    linear.fit({\"train\": s3_train_data})\n",
    "    # deploy a predictor\n",
    "    linear_predictor = linear.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")\n",
    "    #linear_predictor.content_type = \"csv\"\n",
    "    linear_predictor.serializer = CSVSerializer()\n",
    "    linear_predictor.deserializer = JSONDeserializer()\n",
    "    return linear_predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And add another convenience function for setting up a hosting endpoint, making predictions, and evaluating the model. To make predictions, we need to set up a model hosting endpoint. Then we feed test features to the endpoint and receive predicted test labels. To evaluate the models we create in this exercise, we'll capture predicted test labels and compare them to actuals using some common binary classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(linear_predictor, test_features, test_labels, model_name, verbose=True):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a test set given the prediction endpoint.  Return binary classification metrics.\n",
    "    \"\"\"\n",
    "    # split the test data set into 100 batches and evaluate using prediction endpoint\n",
    "    prediction_batches = [\n",
    "        linear_predictor.predict(batch)[\"predictions\"]\n",
    "        for batch in np.array_split(test_features, 100)\n",
    "    ]\n",
    "    # parse raw predictions json to exctract predicted label\n",
    "    test_preds = np.concatenate(\n",
    "        [np.array([x[\"predicted_label\"] for x in batch]) for batch in prediction_batches]\n",
    "    )\n",
    "\n",
    "    # calculate true positives, false positives, true negatives, false negatives\n",
    "    tp = np.logical_and(test_labels, test_preds).sum()\n",
    "    fp = np.logical_and(1 - test_labels, test_preds).sum()\n",
    "    tn = np.logical_and(1 - test_labels, 1 - test_preds).sum()\n",
    "    fn = np.logical_and(test_labels, 1 - test_preds).sum()\n",
    "\n",
    "    # calculate binary classification metrics\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    if verbose:\n",
    "        print(pd.crosstab(test_labels, test_preds, rownames=[\"actuals\"], colnames=[\"predictions\"]))\n",
    "        print(\"\\n{:<11} {:.3f}\".format(\"Recall:\", recall))\n",
    "        print(\"{:<11} {:.3f}\".format(\"Precision:\", precision))\n",
    "        print(\"{:<11} {:.3f}\".format(\"Accuracy:\", accuracy))\n",
    "        print(\"{:<11} {:.3f}\".format(\"F1:\", f1))\n",
    "\n",
    "    return {\n",
    "        \"TP\": tp,\n",
    "        \"FP\": fp,\n",
    "        \"FN\": fn,\n",
    "        \"TN\": tn,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1\": f1,\n",
    "        \"Model\": model_name,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we'll add a convenience function to delete prediction endpoints after we're done with them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_endpoint(predictor):\n",
    "    try:\n",
    "        boto3.client(\"sagemaker\").delete_endpoint(EndpointName=predictor.endpoint)\n",
    "        print(\"Deleted {}\".format(predictor.endpoint))\n",
    "    except:\n",
    "        print(\"Already deleted: {}\".format(predictor.endpoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by training a binary classifier model with the linear learner default settings. Note that we're setting the number of epochs to 10. Also, notice that the the function above has an EARLY STOPPING CRITERIA set to when Recall reaches 0.7. See more on Early Stopping Criteria in https://github.com/aws/amazon-sagemaker-examples/blob/master/scientific_details_of_algorithms/linear_learner_class_weights_loss_functions/linear_learner_class_weights_loss_functions.ipynb\n",
    "\n",
    "With early stopping, we don't have to worry about setting the number of epochs too high. Linear learner will stop training automatically after the model has converged.\n",
    "\n",
    "## Step 2: Initiate hyperpramatereization using the pipeline below.\n",
    "### For each Breakout group members should consider using either one of the celles below (labelled OPTION 1, OPTION 2) and then sharing results to see which are the best. Running both can take a LONG time. So for timely completion please selection either OPTION 1 or 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [OPTION 1]: Training a binary classifier (Logistic Regression) with automated threshold tuning\n",
    "\n",
    "autothresh_hyperparams = {\n",
    "    \"feature_dim\": 12,\n",
    "    \"predictor_type\": \"binary_classifier\",\n",
    "    \"binary_classifier_model_selection_criteria\": \"precision_at_target_recall\",\n",
    "    \"target_recall\": 0.8,\n",
    "    \"epochs\": 10,\n",
    "}\n",
    "autothresh_output_path = \"s3://{}/{}/autothresh/output\".format(bucket_new, prefix)\n",
    "autothresh_predictor = predictor_from_hyperparams(\n",
    "    s3_train_path, autothresh_hyperparams, autothresh_output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for OPTION 1\n",
    "predictors = {\n",
    "    \"Logistic with auto threshold\": autothresh_predictor,\n",
    "         \n",
    "}\n",
    "metrics = {\n",
    "    key: evaluate(predictor, X_test_1, y_test, key, False)\n",
    "    for key, predictor in predictors.items()\n",
    "}\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n",
    "display(\n",
    "    pd.DataFrame(list(metrics.values())).loc[:, [\"Model\", \"Recall\", \"Precision\", \"Accuracy\", \"F1\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [OPTION 2]: Training a binary classifier with hinge loss, balanced class weights, and automated threshold tuning\n",
    "svm_balanced_hyperparams = {\n",
    "    \"feature_dim\": 12,\n",
    "    \"predictor_type\": \"binary_classifier\",\n",
    "    \"loss\": \"hinge_loss\",\n",
    "    \"binary_classifier_model_selection_criteria\": \"precision_at_target_recall\",\n",
    "    \"target_recall\": 0.8,\n",
    "    \"positive_example_weight_mult\": \"balanced\",\n",
    "    \"epochs\": 10,\n",
    "}\n",
    "svm_balanced_output_path = \"s3://{}/{}/svm_balanced/output\".format(bucket_new, prefix)\n",
    "svm_balanced_predictor = predictor_from_hyperparams(\n",
    "    s3_train_path, svm_balanced_hyperparams, svm_balanced_output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for OPTION 2\n",
    "predictors = {\n",
    "    \"Hinge with class weights\": svm_balanced_predictor,\n",
    "    \n",
    "}\n",
    "metrics = {\n",
    "    key: evaluate(predictor, X_test_1, y_test, key, False)\n",
    "    for key, predictor in predictors.items()\n",
    "}\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n",
    "display(\n",
    "    pd.DataFrame(list(metrics.values())).loc[:, [\"Model\", \"Recall\", \"Precision\", \"Accuracy\", \"F1\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, clean up all the predictors\n",
    "for predictor in [\n",
    "    autothresh_predictor,\n",
    "    svm_balanced_predictor,\n",
    "]:\n",
    "    delete_endpoint(predictor)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "635e31ff34c0350df6e9d804eda70786d94f48b17fcc73c378df4ea6ec0d01fd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('fourthbrain')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
